{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d49e3c-3cb3-4a73-8973-1e7083b93ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Input, BatchNormalization, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409d34e3-0bc3-4dce-b6c7-3724dd3955ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    " tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1acd111-1b10-4d0b-beed-caa7dad2f3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a0d1db-2972-47b8-8756-2e7a9742faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "validation_path = 'val'\n",
    "test_path = 'test'\n",
    "\n",
    "def datagen_function(path, aug=False):\n",
    "    if aug == True:\n",
    "        generator = ImageDataGenerator(\n",
    "            rescale = 1 / 255.0,\n",
    "            rotation_range = 10,\n",
    "            zoom_range = 0.1,\n",
    "            horizontal_flip = True\n",
    "        )\n",
    "    else:\n",
    "        generator = ImageDataGenerator(\n",
    "            rescale = 1 / 255.0\n",
    "        )\n",
    "    return generator.flow_from_directory(\n",
    "        path,\n",
    "        target_size = (48,48),\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efb4ff1-210a-441a-88f2-8e742f319e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen_function(train_path, True)\n",
    "validation_gen = datagen_function(validation_path)\n",
    "test_gen = datagen_function(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3707278-c1d6-476f-a4bc-c4c96f1ecd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 3s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,348,743\n",
      "Trainable params: 61,295,623\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "base_resnet= tf.keras.applications.ResNet50(input_shape = (48,48,3), include_top= False, weights = 'imagenet')\n",
    "base_resnet.summary()\n",
    "base_resnet.trainable = False\n",
    "\n",
    "model.add(base_resnet)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1704f536-b38c-4abc-914d-34162bcaa391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 233s 491ms/step - loss: 2.0170 - acc: 0.2454 - val_loss: 1.8139 - val_acc: 0.2494 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 167s 372ms/step - loss: 1.7033 - acc: 0.3184 - val_loss: 1.6661 - val_acc: 0.3260 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 1.5878 - acc: 0.3763 - val_loss: 1.5512 - val_acc: 0.4060 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 167s 372ms/step - loss: 1.4972 - acc: 0.4184 - val_loss: 1.4368 - val_acc: 0.4383 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 163s 362ms/step - loss: 1.4338 - acc: 0.4455 - val_loss: 1.5418 - val_acc: 0.4218 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 171s 380ms/step - loss: 1.3714 - acc: 0.4703 - val_loss: 1.3528 - val_acc: 0.4834 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 161s 358ms/step - loss: 1.3226 - acc: 0.4900 - val_loss: 1.3629 - val_acc: 0.4751 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 168s 375ms/step - loss: 1.2741 - acc: 0.5080 - val_loss: 1.2799 - val_acc: 0.5063 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 170s 378ms/step - loss: 1.2400 - acc: 0.5275 - val_loss: 1.2923 - val_acc: 0.5074 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 1.2267 - acc: 0.5344 - val_loss: 1.2442 - val_acc: 0.5280 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 163s 364ms/step - loss: 1.1903 - acc: 0.5477 - val_loss: 1.2707 - val_acc: 0.5157 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 1.1525 - acc: 0.5621 - val_loss: 1.3289 - val_acc: 0.5040 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 167s 371ms/step - loss: 1.1259 - acc: 0.5731 - val_loss: 1.2361 - val_acc: 0.5341 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 1.0953 - acc: 0.5869 - val_loss: 1.2497 - val_acc: 0.5333 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 161s 358ms/step - loss: 1.0910 - acc: 0.5832 - val_loss: 1.3772 - val_acc: 0.5132 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 170s 378ms/step - loss: 1.0667 - acc: 0.5949 - val_loss: 1.1853 - val_acc: 0.5609 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 197s 437ms/step - loss: 1.1291 - acc: 0.5723 - val_loss: 1.4540 - val_acc: 0.4413 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 1.0690 - acc: 0.5948 - val_loss: 1.2365 - val_acc: 0.5316 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 1.0169 - acc: 0.6140 - val_loss: 1.2319 - val_acc: 0.5341 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 0.9969 - acc: 0.6225 - val_loss: 1.3843 - val_acc: 0.5057 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.9850 - acc: 0.6273 - val_loss: 1.1265 - val_acc: 0.5857 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.9381 - acc: 0.6460 - val_loss: 1.2698 - val_acc: 0.5350 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.9090 - acc: 0.6591 - val_loss: 1.2818 - val_acc: 0.5341 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.8896 - acc: 0.6674 - val_loss: 1.4442 - val_acc: 0.5102 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 0.8656 - acc: 0.6741 - val_loss: 1.5843 - val_acc: 0.4581 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 165s 367ms/step - loss: 0.8331 - acc: 0.6882 - val_loss: 1.2193 - val_acc: 0.5748 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.8139 - acc: 0.6963 - val_loss: 1.4990 - val_acc: 0.5350 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.7903 - acc: 0.7088 - val_loss: 1.2691 - val_acc: 0.5573 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 0.7516 - acc: 0.7209 - val_loss: 1.2518 - val_acc: 0.5874 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 0.8838 - acc: 0.6718 - val_loss: 1.3169 - val_acc: 0.5113 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 161s 359ms/step - loss: 0.8327 - acc: 0.6898 - val_loss: 1.3085 - val_acc: 0.5829 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.7709 - acc: 0.7138 - val_loss: 1.1976 - val_acc: 0.6021 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.7342 - acc: 0.7267 - val_loss: 1.2429 - val_acc: 0.5815 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.7343 - acc: 0.7294 - val_loss: 1.3007 - val_acc: 0.5520 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 165s 366ms/step - loss: 0.7171 - acc: 0.7365 - val_loss: 1.2675 - val_acc: 0.5623 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.7186 - acc: 0.7359 - val_loss: 1.5997 - val_acc: 0.5185 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.6763 - acc: 0.7517 - val_loss: 1.2882 - val_acc: 0.5846 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 166s 368ms/step - loss: 0.6317 - acc: 0.7682 - val_loss: 1.2632 - val_acc: 0.5913 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.6108 - acc: 0.7756 - val_loss: 1.2771 - val_acc: 0.5915 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 0.6481 - acc: 0.7636 - val_loss: 1.3612 - val_acc: 0.5467 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 165s 367ms/step - loss: 0.7027 - acc: 0.7406 - val_loss: 1.2924 - val_acc: 0.5656 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.6366 - acc: 0.7665\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.6366 - acc: 0.7665 - val_loss: 1.5104 - val_acc: 0.5230 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.5138 - acc: 0.8124 - val_loss: 1.3452 - val_acc: 0.6149 - lr: 0.0050\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.4606 - acc: 0.8345 - val_loss: 1.3908 - val_acc: 0.6127 - lr: 0.0050\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 163s 364ms/step - loss: 0.4297 - acc: 0.8435 - val_loss: 1.4257 - val_acc: 0.6088 - lr: 0.0050\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 161s 359ms/step - loss: 0.4116 - acc: 0.8526 - val_loss: 1.6943 - val_acc: 0.5291 - lr: 0.0050\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.3752 - acc: 0.8612 - val_loss: 1.9434 - val_acc: 0.5035 - lr: 0.0050\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.3609 - acc: 0.8683 - val_loss: 1.5733 - val_acc: 0.5929 - lr: 0.0050\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.3425 - acc: 0.8771 - val_loss: 1.5749 - val_acc: 0.6071 - lr: 0.0050\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.3618 - acc: 0.8708 - val_loss: 1.5589 - val_acc: 0.6166 - lr: 0.0050\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.3319 - acc: 0.8815 - val_loss: 1.7388 - val_acc: 0.5918 - lr: 0.0050\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 168s 374ms/step - loss: 0.3556 - acc: 0.8726 - val_loss: 1.5842 - val_acc: 0.6188 - lr: 0.0050\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.3255 - acc: 0.8820 - val_loss: 1.5504 - val_acc: 0.6113 - lr: 0.0050\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 160s 356ms/step - loss: 0.2929 - acc: 0.8970 - val_loss: 1.6793 - val_acc: 0.6135 - lr: 0.0050\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.3001 - acc: 0.8941 - val_loss: 1.6832 - val_acc: 0.6149 - lr: 0.0050\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.2894 - acc: 0.8964 - val_loss: 1.6770 - val_acc: 0.6278 - lr: 0.0050\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 163s 364ms/step - loss: 0.2831 - acc: 0.8969 - val_loss: 1.6795 - val_acc: 0.6172 - lr: 0.0050\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.2544 - acc: 0.9106 - val_loss: 1.7357 - val_acc: 0.6113 - lr: 0.0050\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 0.2462 - acc: 0.9114 - val_loss: 1.7684 - val_acc: 0.6063 - lr: 0.0050\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.2228 - acc: 0.9210 - val_loss: 1.8418 - val_acc: 0.6027 - lr: 0.0050\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - 161s 358ms/step - loss: 0.2512 - acc: 0.9082 - val_loss: 1.8370 - val_acc: 0.5999 - lr: 0.0050\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 160s 357ms/step - loss: 0.2328 - acc: 0.9147 - val_loss: 1.7911 - val_acc: 0.6133 - lr: 0.0050\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 165s 367ms/step - loss: 0.2187 - acc: 0.9223 - val_loss: 1.8008 - val_acc: 0.6135 - lr: 0.0050\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 164s 364ms/step - loss: 0.2093 - acc: 0.9283 - val_loss: 1.9436 - val_acc: 0.5924 - lr: 0.0050\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 165s 368ms/step - loss: 0.2119 - acc: 0.9248 - val_loss: 1.7873 - val_acc: 0.6105 - lr: 0.0050\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.1948 - acc: 0.9314\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "449/449 [==============================] - 163s 362ms/step - loss: 0.1948 - acc: 0.9314 - val_loss: 1.9319 - val_acc: 0.6024 - lr: 0.0050\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 164s 364ms/step - loss: 0.1697 - acc: 0.9424 - val_loss: 1.8703 - val_acc: 0.6211 - lr: 0.0025\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.1461 - acc: 0.9507 - val_loss: 2.0377 - val_acc: 0.6141 - lr: 0.0025\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 166s 369ms/step - loss: 0.1336 - acc: 0.9526 - val_loss: 2.0533 - val_acc: 0.6141 - lr: 0.0025\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.1276 - acc: 0.9560 - val_loss: 2.0363 - val_acc: 0.6205 - lr: 0.0025\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.1250 - acc: 0.9573 - val_loss: 2.0542 - val_acc: 0.6149 - lr: 0.0025\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 162s 360ms/step - loss: 0.1135 - acc: 0.9609 - val_loss: 2.1452 - val_acc: 0.6060 - lr: 0.0025\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.1087 - acc: 0.9616 - val_loss: 2.0931 - val_acc: 0.6138 - lr: 0.0025\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - 165s 369ms/step - loss: 0.1093 - acc: 0.9621 - val_loss: 2.1348 - val_acc: 0.6202 - lr: 0.0025\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.1055 - acc: 0.9636 - val_loss: 2.1463 - val_acc: 0.6191 - lr: 0.0025\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.1016 - acc: 0.9640\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "449/449 [==============================] - 160s 357ms/step - loss: 0.1016 - acc: 0.9640 - val_loss: 2.3024 - val_acc: 0.6085 - lr: 0.0025\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.0960 - acc: 0.9656 - val_loss: 2.2160 - val_acc: 0.6108 - lr: 0.0012\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.0871 - acc: 0.9703 - val_loss: 2.2096 - val_acc: 0.6080 - lr: 0.0012\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0845 - acc: 0.9710 - val_loss: 2.2178 - val_acc: 0.6174 - lr: 0.0012\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 163s 362ms/step - loss: 0.0781 - acc: 0.9730 - val_loss: 2.2443 - val_acc: 0.6160 - lr: 0.0012\n",
      "Epoch 81/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.0767 - acc: 0.9737 - val_loss: 2.2976 - val_acc: 0.6144 - lr: 0.0012\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 0.0747 - acc: 0.9746 - val_loss: 2.2510 - val_acc: 0.6239 - lr: 0.0012\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 166s 370ms/step - loss: 0.0730 - acc: 0.9756 - val_loss: 2.3054 - val_acc: 0.6194 - lr: 0.0012\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 167s 372ms/step - loss: 0.0683 - acc: 0.9771 - val_loss: 2.3172 - val_acc: 0.6261 - lr: 0.0012\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.0663 - acc: 0.9775 - val_loss: 2.3591 - val_acc: 0.6222 - lr: 0.0012\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9779\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "449/449 [==============================] - 162s 362ms/step - loss: 0.0664 - acc: 0.9779 - val_loss: 2.3798 - val_acc: 0.6133 - lr: 0.0012\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.0636 - acc: 0.9783 - val_loss: 2.3656 - val_acc: 0.6227 - lr: 6.2500e-04\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0601 - acc: 0.9789 - val_loss: 2.3976 - val_acc: 0.6186 - lr: 6.2500e-04\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 163s 363ms/step - loss: 0.0568 - acc: 0.9797 - val_loss: 2.3972 - val_acc: 0.6194 - lr: 6.2500e-04\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 0.0562 - acc: 0.9808 - val_loss: 2.4362 - val_acc: 0.6227 - lr: 6.2500e-04\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.0569 - acc: 0.9794 - val_loss: 2.4546 - val_acc: 0.6219 - lr: 6.2500e-04\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 164s 366ms/step - loss: 0.0550 - acc: 0.9807 - val_loss: 2.4490 - val_acc: 0.6180 - lr: 6.2500e-04\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - 161s 358ms/step - loss: 0.0547 - acc: 0.9812 - val_loss: 2.4178 - val_acc: 0.6213 - lr: 6.2500e-04\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 162s 362ms/step - loss: 0.0523 - acc: 0.9812 - val_loss: 2.4583 - val_acc: 0.6141 - lr: 6.2500e-04\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0563 - acc: 0.9800 - val_loss: 2.4638 - val_acc: 0.6183 - lr: 6.2500e-04\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.9828\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "449/449 [==============================] - 164s 365ms/step - loss: 0.0486 - acc: 0.9828 - val_loss: 2.4741 - val_acc: 0.6202 - lr: 6.2500e-04\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0533 - acc: 0.9813 - val_loss: 2.4630 - val_acc: 0.6158 - lr: 3.1250e-04\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0498 - acc: 0.9833 - val_loss: 2.4850 - val_acc: 0.6177 - lr: 3.1250e-04\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 160s 357ms/step - loss: 0.0473 - acc: 0.9832 - val_loss: 2.4980 - val_acc: 0.6172 - lr: 3.1250e-04\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 162s 361ms/step - loss: 0.0472 - acc: 0.9829 - val_loss: 2.4979 - val_acc: 0.6213 - lr: 3.1250e-04\n"
     ]
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.0001, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/vgg16.h5', monitor='val_acc', save_best_only=True, save_freq=\"epoch\")\n",
    "reduce_lr2 = ReduceLROnPlateau(monitor='val_acc', mode='max', factor = 0.5, patience = 10, min_lr = 0.000001, verbose = 1)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics= 'acc')\n",
    "history = model.fit(train_gen,validation_data = validation_gen, epochs = 100, callbacks = [reduce_lr2, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54b5cf9-9d4a-4f85-90ee-997104273c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model_f\u001b[38;5;241m.\u001b[39madd(base_resnet)\n\u001b[0;32m      9\u001b[0m model_f\u001b[38;5;241m.\u001b[39madd(Flatten())\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m model_f\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.4\u001b[39m))\n\u001b[0;32m     13\u001b[0m model_f\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1024\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e72d39-e786-4e6b-a303-8280faf70424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,348,743\n",
      "Trainable params: 38,815,751\n",
      "Non-trainable params: 22,532,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "base_resnet= tf.keras.applications.ResNet50(input_shape = (48,48,3), include_top= False, weights = 'imagenet')\n",
    "base_resnet.summary()\n",
    "for layer in base_resnet.layers[:170]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(base_resnet)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5ca5ba-5b4a-4685-b190-b9cf8e124ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 186s 406ms/step - loss: 1.8070 - acc: 0.2421 - val_loss: 1.7735 - val_acc: 0.2639 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.7730 - acc: 0.2649 - val_loss: 1.8334 - val_acc: 0.2313 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 44s 99ms/step - loss: 1.7542 - acc: 0.2811 - val_loss: 1.7393 - val_acc: 0.2901 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.7467 - acc: 0.2830 - val_loss: 1.7526 - val_acc: 0.2705 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 45s 101ms/step - loss: 1.7353 - acc: 0.2911 - val_loss: 1.7137 - val_acc: 0.2951 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.7289 - acc: 0.2980 - val_loss: 1.7194 - val_acc: 0.2820 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 43s 96ms/step - loss: 1.7219 - acc: 0.2984 - val_loss: 1.7231 - val_acc: 0.2845 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 43s 97ms/step - loss: 1.7053 - acc: 0.3097 - val_loss: 1.7468 - val_acc: 0.2731 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 46s 103ms/step - loss: 1.7060 - acc: 0.3097 - val_loss: 1.7325 - val_acc: 0.2992 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 44s 98ms/step - loss: 1.6978 - acc: 0.3176 - val_loss: 1.6861 - val_acc: 0.3257 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6967 - acc: 0.3167 - val_loss: 1.7159 - val_acc: 0.3082 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6938 - acc: 0.3186 - val_loss: 1.7169 - val_acc: 0.2809 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 41s 92ms/step - loss: 1.6868 - acc: 0.3218 - val_loss: 1.8288 - val_acc: 0.2561 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 44s 98ms/step - loss: 1.6847 - acc: 0.3220 - val_loss: 1.6854 - val_acc: 0.3405 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6803 - acc: 0.3289 - val_loss: 1.7372 - val_acc: 0.2956 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6751 - acc: 0.3309 - val_loss: 1.6900 - val_acc: 0.3332 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6660 - acc: 0.3358 - val_loss: 1.6817 - val_acc: 0.3215 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 44s 98ms/step - loss: 1.6645 - acc: 0.3413 - val_loss: 1.6932 - val_acc: 0.3469 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 44s 97ms/step - loss: 1.6577 - acc: 0.3416 - val_loss: 1.6699 - val_acc: 0.3505 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6616 - acc: 0.3392 - val_loss: 1.6845 - val_acc: 0.3093 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 40s 90ms/step - loss: 1.6572 - acc: 0.3457 - val_loss: 1.7656 - val_acc: 0.2742 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6517 - acc: 0.3458 - val_loss: 1.6802 - val_acc: 0.3240 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6508 - acc: 0.3470 - val_loss: 1.6656 - val_acc: 0.3196 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6445 - acc: 0.3510 - val_loss: 1.6658 - val_acc: 0.3472 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 44s 97ms/step - loss: 1.6376 - acc: 0.3513 - val_loss: 1.6536 - val_acc: 0.3564 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6418 - acc: 0.3492 - val_loss: 1.6835 - val_acc: 0.3182 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6342 - acc: 0.3527 - val_loss: 1.7218 - val_acc: 0.2862 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 1.6319 - acc: 0.3605 - val_loss: 1.7062 - val_acc: 0.2845 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 45s 101ms/step - loss: 1.6239 - acc: 0.3615 - val_loss: 1.6485 - val_acc: 0.3597 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 43s 97ms/step - loss: 1.6269 - acc: 0.3599 - val_loss: 1.6643 - val_acc: 0.3176 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 48s 107ms/step - loss: 1.6200 - acc: 0.3613 - val_loss: 1.6522 - val_acc: 0.3736 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 45s 101ms/step - loss: 1.6256 - acc: 0.3619 - val_loss: 1.6801 - val_acc: 0.3419 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 45s 100ms/step - loss: 1.6218 - acc: 0.3620 - val_loss: 1.6607 - val_acc: 0.3313 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 45s 101ms/step - loss: 1.6219 - acc: 0.3607 - val_loss: 1.7089 - val_acc: 0.3174 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 45s 100ms/step - loss: 1.6131 - acc: 0.3670 - val_loss: 1.6653 - val_acc: 0.3249 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.6100 - acc: 0.3657 - val_loss: 1.6302 - val_acc: 0.3550 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.6123 - acc: 0.3672 - val_loss: 1.6378 - val_acc: 0.3402 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.6071 - acc: 0.3701 - val_loss: 1.6970 - val_acc: 0.3023 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.6055 - acc: 0.3684 - val_loss: 1.6777 - val_acc: 0.3040 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.6026 - acc: 0.3701 - val_loss: 1.6917 - val_acc: 0.3374 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.6043 - acc: 0.3717\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.6043 - acc: 0.3717 - val_loss: 1.6823 - val_acc: 0.3093 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5847 - acc: 0.3785 - val_loss: 1.6488 - val_acc: 0.3500 - lr: 0.0050\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 46s 102ms/step - loss: 1.5864 - acc: 0.3805 - val_loss: 1.6070 - val_acc: 0.3750 - lr: 0.0050\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5749 - acc: 0.3845 - val_loss: 1.6123 - val_acc: 0.3539 - lr: 0.0050\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5751 - acc: 0.3869 - val_loss: 1.5926 - val_acc: 0.3700 - lr: 0.0050\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 46s 102ms/step - loss: 1.5768 - acc: 0.3830 - val_loss: 1.5909 - val_acc: 0.3781 - lr: 0.0050\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5703 - acc: 0.3856 - val_loss: 1.6374 - val_acc: 0.3402 - lr: 0.0050\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5697 - acc: 0.3891 - val_loss: 1.6268 - val_acc: 0.3720 - lr: 0.0050\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5697 - acc: 0.3856 - val_loss: 1.6133 - val_acc: 0.3689 - lr: 0.0050\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5622 - acc: 0.3899 - val_loss: 1.6765 - val_acc: 0.3101 - lr: 0.0050\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 46s 102ms/step - loss: 1.5611 - acc: 0.3919 - val_loss: 1.5798 - val_acc: 0.3789 - lr: 0.0050\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5648 - acc: 0.3884 - val_loss: 1.6019 - val_acc: 0.3678 - lr: 0.0050\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5625 - acc: 0.3911 - val_loss: 1.6086 - val_acc: 0.3658 - lr: 0.0050\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5625 - acc: 0.3894 - val_loss: 1.6003 - val_acc: 0.3764 - lr: 0.0050\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5561 - acc: 0.3939 - val_loss: 1.6750 - val_acc: 0.3399 - lr: 0.0050\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5548 - acc: 0.3950 - val_loss: 1.6360 - val_acc: 0.3282 - lr: 0.0050\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5528 - acc: 0.3952 - val_loss: 1.6299 - val_acc: 0.3508 - lr: 0.0050\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5566 - acc: 0.3939 - val_loss: 1.5983 - val_acc: 0.3784 - lr: 0.0050\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5541 - acc: 0.3921 - val_loss: 1.5910 - val_acc: 0.3761 - lr: 0.0050\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5572 - acc: 0.3936 - val_loss: 1.6003 - val_acc: 0.3778 - lr: 0.0050\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.5493 - acc: 0.3965\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5493 - acc: 0.3965 - val_loss: 1.5872 - val_acc: 0.3714 - lr: 0.0050\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 45s 101ms/step - loss: 1.5374 - acc: 0.4028 - val_loss: 1.5763 - val_acc: 0.3803 - lr: 0.0025\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 45s 100ms/step - loss: 1.5372 - acc: 0.4025 - val_loss: 1.5830 - val_acc: 0.3912 - lr: 0.0025\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 46s 102ms/step - loss: 1.5304 - acc: 0.4066 - val_loss: 1.5806 - val_acc: 0.4026 - lr: 0.0025\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5305 - acc: 0.4068 - val_loss: 1.5861 - val_acc: 0.3725 - lr: 0.0025\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5339 - acc: 0.4058 - val_loss: 1.5927 - val_acc: 0.3784 - lr: 0.0025\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5307 - acc: 0.4058 - val_loss: 1.5664 - val_acc: 0.3926 - lr: 0.0025\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 42s 95ms/step - loss: 1.5283 - acc: 0.4047 - val_loss: 1.5620 - val_acc: 0.3887 - lr: 0.0025\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5305 - acc: 0.4016 - val_loss: 1.5897 - val_acc: 0.3619 - lr: 0.0025\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - 45s 99ms/step - loss: 1.5254 - acc: 0.4070 - val_loss: 1.5919 - val_acc: 0.3803 - lr: 0.0025\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 43s 94ms/step - loss: 1.5249 - acc: 0.4068 - val_loss: 1.5745 - val_acc: 0.3943 - lr: 0.0025\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5230 - acc: 0.4075 - val_loss: 1.5739 - val_acc: 0.3870 - lr: 0.0025\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5215 - acc: 0.4107 - val_loss: 1.5872 - val_acc: 0.3664 - lr: 0.0025\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.5261 - acc: 0.4082\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5261 - acc: 0.4082 - val_loss: 1.5746 - val_acc: 0.3750 - lr: 0.0025\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5161 - acc: 0.4124 - val_loss: 1.5602 - val_acc: 0.3879 - lr: 0.0012\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - 42s 95ms/step - loss: 1.5064 - acc: 0.4135 - val_loss: 1.5514 - val_acc: 0.3982 - lr: 0.0012\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5083 - acc: 0.4131 - val_loss: 1.5639 - val_acc: 0.3845 - lr: 0.0012\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5085 - acc: 0.4145 - val_loss: 1.5558 - val_acc: 0.4001 - lr: 0.0012\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5068 - acc: 0.4135 - val_loss: 1.5540 - val_acc: 0.3996 - lr: 0.0012\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5114 - acc: 0.4132 - val_loss: 1.5495 - val_acc: 0.3948 - lr: 0.0012\n",
      "Epoch 81/100\n",
      "449/449 [==============================] - 47s 104ms/step - loss: 1.5055 - acc: 0.4162 - val_loss: 1.5436 - val_acc: 0.4043 - lr: 0.0012\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 44s 98ms/step - loss: 1.5044 - acc: 0.4177 - val_loss: 1.5502 - val_acc: 0.4009 - lr: 0.0012\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 44s 98ms/step - loss: 1.5028 - acc: 0.4170 - val_loss: 1.5489 - val_acc: 0.3948 - lr: 0.0012\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 43s 97ms/step - loss: 1.5052 - acc: 0.4166 - val_loss: 1.5544 - val_acc: 0.3923 - lr: 0.0012\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 43s 96ms/step - loss: 1.5010 - acc: 0.4212 - val_loss: 1.5534 - val_acc: 0.3940 - lr: 0.0012\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5053 - acc: 0.4167 - val_loss: 1.5518 - val_acc: 0.3954 - lr: 0.0012\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4999 - acc: 0.4208 - val_loss: 1.5449 - val_acc: 0.3937 - lr: 0.0012\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.5004 - acc: 0.4175 - val_loss: 1.5650 - val_acc: 0.3823 - lr: 0.0012\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 42s 95ms/step - loss: 1.5014 - acc: 0.4177 - val_loss: 1.5406 - val_acc: 0.3998 - lr: 0.0012\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.4986 - acc: 0.4162 - val_loss: 1.5428 - val_acc: 0.4004 - lr: 0.0012\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.5024 - acc: 0.4204\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.5024 - acc: 0.4204 - val_loss: 1.5514 - val_acc: 0.4001 - lr: 0.0012\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.4971 - acc: 0.4202 - val_loss: 1.5417 - val_acc: 0.3990 - lr: 6.2500e-04\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4971 - acc: 0.4205 - val_loss: 1.5427 - val_acc: 0.3906 - lr: 6.2500e-04\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.4959 - acc: 0.4212 - val_loss: 1.5416 - val_acc: 0.4007 - lr: 6.2500e-04\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4925 - acc: 0.4188 - val_loss: 1.5438 - val_acc: 0.4029 - lr: 6.2500e-04\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - 43s 95ms/step - loss: 1.4970 - acc: 0.4190 - val_loss: 1.5432 - val_acc: 0.3968 - lr: 6.2500e-04\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4904 - acc: 0.4227 - val_loss: 1.5370 - val_acc: 0.4007 - lr: 6.2500e-04\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4946 - acc: 0.4206 - val_loss: 1.5418 - val_acc: 0.3957 - lr: 6.2500e-04\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4932 - acc: 0.4207 - val_loss: 1.5355 - val_acc: 0.3987 - lr: 6.2500e-04\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.4907 - acc: 0.4213 - val_loss: 1.5391 - val_acc: 0.3968 - lr: 6.2500e-04\n"
     ]
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.0001, nesterov=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/resnet50.h5', monitor='val_acc', save_best_only=True, save_freq=\"epoch\")\n",
    "reduce_lr2 = ReduceLROnPlateau(monitor='val_acc', mode='max', factor = 0.5, patience = 10, min_lr = 0.000001, verbose = 1)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics= 'acc')\n",
    "history = model.fit(train_gen,validation_data = validation_gen, epochs = 100, callbacks = [reduce_lr2, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bac3566-5fec-4da8-8b7f-7ccbb20c59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:170]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd3427a-a2cb-4992-a7ed-ce55a92051e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 76s 153ms/step - loss: 1.5894 - acc: 0.3852 - val_loss: 1.8339 - val_acc: 0.2385 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 71s 157ms/step - loss: 1.3057 - acc: 0.4998 - val_loss: 1.3383 - val_acc: 0.4932 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 74s 164ms/step - loss: 1.2116 - acc: 0.5370 - val_loss: 1.6084 - val_acc: 0.4324 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 73s 162ms/step - loss: 1.1651 - acc: 0.5611 - val_loss: 1.2492 - val_acc: 0.5135 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 1.1226 - acc: 0.5768 - val_loss: 1.4619 - val_acc: 0.4216 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 71s 159ms/step - loss: 1.1030 - acc: 0.5826 - val_loss: 1.1517 - val_acc: 0.5726 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 1.0513 - acc: 0.6049 - val_loss: 1.1120 - val_acc: 0.5743 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 67s 148ms/step - loss: 1.0449 - acc: 0.6030 - val_loss: 1.3113 - val_acc: 0.5127 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 66s 147ms/step - loss: 1.0274 - acc: 0.6129 - val_loss: 1.1723 - val_acc: 0.5506 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 0.9853 - acc: 0.6291 - val_loss: 1.1067 - val_acc: 0.5871 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 67s 148ms/step - loss: 0.9487 - acc: 0.6426 - val_loss: 1.1201 - val_acc: 0.5779 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 67s 148ms/step - loss: 0.9024 - acc: 0.6625 - val_loss: 1.2924 - val_acc: 0.5339 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.8850 - acc: 0.6682 - val_loss: 1.1263 - val_acc: 0.5837 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.9161 - acc: 0.6598 - val_loss: 1.1893 - val_acc: 0.5542 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 72s 160ms/step - loss: 0.8804 - acc: 0.6708 - val_loss: 1.1514 - val_acc: 0.5876 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 0.8434 - acc: 0.6846 - val_loss: 1.1025 - val_acc: 0.5935 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 72s 159ms/step - loss: 0.8326 - acc: 0.6901 - val_loss: 1.1084 - val_acc: 0.6057 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.8560 - acc: 0.6780 - val_loss: 1.2060 - val_acc: 0.5737 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.8241 - acc: 0.6894 - val_loss: 1.1527 - val_acc: 0.5795 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 74s 165ms/step - loss: 0.7851 - acc: 0.7052 - val_loss: 1.1194 - val_acc: 0.6135 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.7908 - acc: 0.7058 - val_loss: 1.1540 - val_acc: 0.6035 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.7247 - acc: 0.7302 - val_loss: 1.1594 - val_acc: 0.5946 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.6816 - acc: 0.7488 - val_loss: 1.1628 - val_acc: 0.6108 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.6372 - acc: 0.7674 - val_loss: 1.2469 - val_acc: 0.5812 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.6104 - acc: 0.7779 - val_loss: 1.4583 - val_acc: 0.5330 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 72s 160ms/step - loss: 0.5925 - acc: 0.7824 - val_loss: 1.2062 - val_acc: 0.6158 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.5399 - acc: 0.8055 - val_loss: 1.3227 - val_acc: 0.6016 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 74s 165ms/step - loss: 0.5152 - acc: 0.8123 - val_loss: 1.2820 - val_acc: 0.6222 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.4702 - acc: 0.8277 - val_loss: 1.3340 - val_acc: 0.6222 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.4583 - acc: 0.8355 - val_loss: 1.3755 - val_acc: 0.6030 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.4326 - acc: 0.8441 - val_loss: 1.3820 - val_acc: 0.6152 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 71s 159ms/step - loss: 0.4246 - acc: 0.8456 - val_loss: 1.2618 - val_acc: 0.6395 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.3946 - acc: 0.8606 - val_loss: 1.3287 - val_acc: 0.6230 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.3704 - acc: 0.8658 - val_loss: 1.4085 - val_acc: 0.6269 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.3422 - acc: 0.8760 - val_loss: 1.4576 - val_acc: 0.6322 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.3258 - acc: 0.8827 - val_loss: 1.5551 - val_acc: 0.6135 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.3159 - acc: 0.8882 - val_loss: 1.4361 - val_acc: 0.6236 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.3088 - acc: 0.8901 - val_loss: 1.5528 - val_acc: 0.6172 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.2769 - acc: 0.9033 - val_loss: 1.5608 - val_acc: 0.6213 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.2645 - acc: 0.9052 - val_loss: 1.5767 - val_acc: 0.6166 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.2585 - acc: 0.9099 - val_loss: 1.6172 - val_acc: 0.6289 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.2354 - acc: 0.9172\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.2354 - acc: 0.9172 - val_loss: 1.6438 - val_acc: 0.6361 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.1811 - acc: 0.9365 - val_loss: 1.7252 - val_acc: 0.6330 - lr: 0.0050\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.1474 - acc: 0.9496 - val_loss: 1.8550 - val_acc: 0.6286 - lr: 0.0050\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 72s 159ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 1.8187 - val_acc: 0.6453 - lr: 0.0050\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.1240 - acc: 0.9565 - val_loss: 1.8601 - val_acc: 0.6389 - lr: 0.0050\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 71s 159ms/step - loss: 0.1114 - acc: 0.9623 - val_loss: 1.8681 - val_acc: 0.6562 - lr: 0.0050\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.1075 - acc: 0.9633 - val_loss: 1.9132 - val_acc: 0.6484 - lr: 0.0050\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.1018 - acc: 0.9642 - val_loss: 1.9682 - val_acc: 0.6464 - lr: 0.0050\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0934 - acc: 0.9673 - val_loss: 1.9971 - val_acc: 0.6445 - lr: 0.0050\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0915 - acc: 0.9688 - val_loss: 2.0633 - val_acc: 0.6436 - lr: 0.0050\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0854 - acc: 0.9709 - val_loss: 2.0368 - val_acc: 0.6539 - lr: 0.0050\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0801 - acc: 0.9724 - val_loss: 2.0892 - val_acc: 0.6459 - lr: 0.0050\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0781 - acc: 0.9719 - val_loss: 2.1014 - val_acc: 0.6548 - lr: 0.0050\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0792 - acc: 0.9737 - val_loss: 2.0382 - val_acc: 0.6525 - lr: 0.0050\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 72s 160ms/step - loss: 0.0755 - acc: 0.9733 - val_loss: 2.0776 - val_acc: 0.6573 - lr: 0.0050\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0728 - acc: 0.9753 - val_loss: 2.1319 - val_acc: 0.6464 - lr: 0.0050\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0692 - acc: 0.9771 - val_loss: 2.0989 - val_acc: 0.6517 - lr: 0.0050\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.0642 - acc: 0.9773 - val_loss: 2.1178 - val_acc: 0.6570 - lr: 0.0050\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 72s 160ms/step - loss: 0.0642 - acc: 0.9768 - val_loss: 2.1650 - val_acc: 0.6606 - lr: 0.0050\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0602 - acc: 0.9790 - val_loss: 2.1743 - val_acc: 0.6553 - lr: 0.0050\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0574 - acc: 0.9794 - val_loss: 2.1840 - val_acc: 0.6598 - lr: 0.0050\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.0597 - acc: 0.9793 - val_loss: 2.2235 - val_acc: 0.6545 - lr: 0.0050\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0586 - acc: 0.9799 - val_loss: 2.3108 - val_acc: 0.6562 - lr: 0.0050\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0563 - acc: 0.9806 - val_loss: 2.1980 - val_acc: 0.6492 - lr: 0.0050\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0514 - acc: 0.9823 - val_loss: 2.2771 - val_acc: 0.6551 - lr: 0.0050\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.0523 - acc: 0.9820 - val_loss: 2.2951 - val_acc: 0.6567 - lr: 0.0050\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0518 - acc: 0.9814 - val_loss: 2.2546 - val_acc: 0.6486 - lr: 0.0050\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.0517 - acc: 0.9823 - val_loss: 2.2706 - val_acc: 0.6556 - lr: 0.0050\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.0504 - acc: 0.9815\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "449/449 [==============================] - 68s 150ms/step - loss: 0.0504 - acc: 0.9815 - val_loss: 2.2718 - val_acc: 0.6559 - lr: 0.0050\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0425 - acc: 0.9845 - val_loss: 2.3230 - val_acc: 0.6534 - lr: 0.0025\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 0.0398 - acc: 0.9856 - val_loss: 2.3236 - val_acc: 0.6559 - lr: 0.0025\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 0.0373 - acc: 0.9861 - val_loss: 2.3806 - val_acc: 0.6623 - lr: 0.0025\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0355 - acc: 0.9865 - val_loss: 2.3776 - val_acc: 0.6612 - lr: 0.0025\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0358 - acc: 0.9866 - val_loss: 2.3747 - val_acc: 0.6531 - lr: 0.0025\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0338 - acc: 0.9873 - val_loss: 2.4025 - val_acc: 0.6578 - lr: 0.0025\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0342 - acc: 0.9881 - val_loss: 2.4130 - val_acc: 0.6567 - lr: 0.0025\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0321 - acc: 0.9876 - val_loss: 2.4046 - val_acc: 0.6506 - lr: 0.0025\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0296 - acc: 0.9892 - val_loss: 2.4288 - val_acc: 0.6606 - lr: 0.0025\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0289 - acc: 0.9896 - val_loss: 2.4690 - val_acc: 0.6545 - lr: 0.0025\n",
      "Epoch 81/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0296 - acc: 0.9891 - val_loss: 2.4642 - val_acc: 0.6609 - lr: 0.0025\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 0.0298 - acc: 0.9891 - val_loss: 2.5191 - val_acc: 0.6637 - lr: 0.0025\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 0.0274 - acc: 0.9898 - val_loss: 2.4847 - val_acc: 0.6668 - lr: 0.0025\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0270 - acc: 0.9894 - val_loss: 2.5000 - val_acc: 0.6615 - lr: 0.0025\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0261 - acc: 0.9903 - val_loss: 2.5399 - val_acc: 0.6645 - lr: 0.0025\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0273 - acc: 0.9902 - val_loss: 2.5580 - val_acc: 0.6606 - lr: 0.0025\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0265 - acc: 0.9905 - val_loss: 2.5768 - val_acc: 0.6578 - lr: 0.0025\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0267 - acc: 0.9902 - val_loss: 2.5484 - val_acc: 0.6551 - lr: 0.0025\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0250 - acc: 0.9908 - val_loss: 2.5880 - val_acc: 0.6601 - lr: 0.0025\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0263 - acc: 0.9897 - val_loss: 2.5649 - val_acc: 0.6578 - lr: 0.0025\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0253 - acc: 0.9897 - val_loss: 2.6018 - val_acc: 0.6573 - lr: 0.0025\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 67s 150ms/step - loss: 0.0254 - acc: 0.9901 - val_loss: 2.5878 - val_acc: 0.6604 - lr: 0.0025\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9904\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0258 - acc: 0.9904 - val_loss: 2.6054 - val_acc: 0.6601 - lr: 0.0025\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0227 - acc: 0.9911 - val_loss: 2.6115 - val_acc: 0.6604 - lr: 0.0012\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0220 - acc: 0.9921 - val_loss: 2.6428 - val_acc: 0.6592 - lr: 0.0012\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0212 - acc: 0.9924 - val_loss: 2.6604 - val_acc: 0.6567 - lr: 0.0012\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0207 - acc: 0.9917 - val_loss: 2.6597 - val_acc: 0.6565 - lr: 0.0012\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0209 - acc: 0.9917 - val_loss: 2.6905 - val_acc: 0.6553 - lr: 0.0012\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0219 - acc: 0.9911 - val_loss: 2.6853 - val_acc: 0.6567 - lr: 0.0012\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 0.0212 - acc: 0.9919 - val_loss: 2.6823 - val_acc: 0.6542 - lr: 0.0012\n"
     ]
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.0001, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics= 'acc')\n",
    "history = model.fit(train_gen,validation_data = validation_gen, epochs = 100, callbacks = [reduce_lr2, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
